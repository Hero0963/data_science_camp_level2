{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG5qD+U6pkFhh3JbEcJzit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hero0963/data_science_camp_level2/blob/main/task08/dscamp_lv2_task08_hw01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 機器學習可以分成「監督式學習」與「非監督式學習」，請分別舉一個應用的例子。**    \n",
        "  監督式學習：  \n",
        "用一系列的貓狗圖片，並且每一張都有明確註明哪個是貓哪個是狗(標籤)作為訓練資料，讓模型學習。  \n",
        "目的是辨識圖片中的動物是貓還是狗。  \n",
        "\n",
        "  非監督學習:  \n",
        "K-means 根據顧客的消費習慣將顧客分成不同的群組，以便進行更精確的行銷。  "
      ],
      "metadata": {
        "id": "AwuJOmz9-lau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. 線性回歸（Linear Regression）能夠利用一個條線代表一組資料的分佈，請問線性回歸是如何找出代表資料點的線？**  \n",
        "\n",
        "  ref = https://ithelp.ithome.com.tw/articles/10187739  \n",
        "  給定資料點所構成的集合 $D = \\{ D_1, D_2,　D_3,..., D_k \\}$，其中 $D_i = (x_{i1}, x_{i2}, ...,x_{in})$ 。  \n",
        "  我們希望用一個線性函數形如 $L = W_1x_1 + W_2x_2 + ... + W_nx_n + b$ 使得點集合與函數間的誤差最小，一般採用誤差算法為 mean-square error。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8l0TfSJeBRH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. 通常越複雜的模型越有可能出現過擬合（Overfitting）的狀況，請問什麼是 Overfitting 呢？實際上又該怎麼避免或解決？**  \n",
        "  overfitting: 模型在 train set 上表現好，實際上表現不好。  \n",
        "解決方案: 給更多資料、降低模型複雜度、正則化_讓Loss Function更平滑，抗雜訊干擾能力越大。  \n"
      ],
      "metadata": {
        "id": "Zf6E60Ddmldi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. 承上題，要如何從模型的結果中觀察到可能出現過擬合（Overfitting）的狀況？**  \n",
        "  如果模型在訓練集上表現良好，但在測試集上表現不佳，則可能存在過擬合問題。  \n",
        "  實務上常使用 K-fold cross-validation 方法來預防模型過度擬合。  \n",
        "在這種方法中，將訓練集分成 K 個子集，然後將每個子集用作驗證集，其餘子集用於訓練。  \n",
        "每輪訓練中使用不同的驗證集評估模型的性能，因此可以有效避免過擬合。  \n",
        "ref = https://jason-chen-1992.weebly.com/home/-cross-validation\n"
      ],
      "metadata": {
        "id": "vTSvn-BvnACF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. PCA 模型能夠將高維度的資料集轉換成比較低的維度，請問什麼情況下該這麼做？**  \n",
        "\n",
        "  PCA: 將n維降到d維，使用時機如下：  \n",
        "a. 資料集中有很多冗餘的特徵時。  \n",
        "b. 資料集中存在噪聲或者不必要的變量。  \n",
        "c. 資料集中存在多個相關的特徵時，可以使用 PCA 模型來將這些相關特徵轉換成一個新的特徵。 \n",
        "\n",
        "另外，使用 PCA 進行降維時，需注意先對資料進行正規化處理，以免不同特徵之間的尺度差異對模型造成影響。  \n",
        "ex: 特徵中含有：  \n",
        "* 身高，單位為公尺，數值範圍為 1.6 ~ 1.8。  \n",
        "* 體重，單位為公斤，數值範圍為 50 ~ 110。  \n"
      ],
      "metadata": {
        "id": "JymAZcCAo-a7"
      }
    }
  ]
}