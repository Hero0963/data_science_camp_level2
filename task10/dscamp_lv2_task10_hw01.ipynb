{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNokTgGo4bop1PKKi0mSqcb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hero0963/data_science_camp_level2/blob/main/task10/dscamp_lv2_task10_hw01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 在分類模型中我們可以利用「Recall」和「Precision」進行模型評估，請問這兩種方法有什麼差別？** \n",
        " \n",
        "  召回率 (Recall) 是指實際為正類別的樣本中，被分為正類別的比例。  \n",
        "  召回率越高，表示模型能夠更好地捕捉到實際為正類別的樣本，降低了對正樣本的漏判率。  \n",
        "\n",
        "  精確率 (Precision) 是指被分為正類別的樣本中，實際上為正類別的比例。  \n",
        "  精確率越高，表示模型能夠更好地避免對負樣本的錯誤預測。  \n"
      ],
      "metadata": {
        "id": "BQ0T8btKLScE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. 在回歸模型中我們可以利用「MSE」和「MAE」進行模型評估，請問這兩種方法有什麼差別？**  \n",
        "\n",
        "  MAE (Mean Absolute Error) 表示預測值和實際值之間的絕對誤差的平均值。  \n",
        "  MSE (Mean Squared Error) 表示預測值和實際值之間的平方誤差的平均值。  \n",
        "\n",
        "  它們在衡量預測誤差的方式上有一些差異。  \n",
        "  MSE將大誤差的影響放大，因為誤差被平方了，而MAE則對所有誤差一視同仁。  \n",
        "  由於MSE計算的是平方誤差，因此它的值通常會比MAE大，且會受到極端誤差值的影響。  \n",
        "  相對地，MAE的值會比較接近實際誤差的平均值。  \n",
        "  選擇使用MSE還是MAE取決於具體的應用場景和需求。\n",
        "\n"
      ],
      "metadata": {
        "id": "2pCY4sgOMF6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. 請問為什麼需要導入「交叉驗證（Cross-Validation）」的機制？**\n",
        "\n",
        "  交叉驗證將數據集分為 k 個相等的子集，然後進行 k 次實驗，每次選擇其中一個子集作為測試集，其餘子集作為訓練集。最終，將這些實驗的結果平均化，得到一個模型的評估分數。  \n",
        "\n",
        "  交叉驗證提供了一種更準確地評估和選擇機器學習模型的方法，能夠更好地利用有限的數據，並且可以幫助避免模型選擇中的偏差和過擬合問題。  \n"
      ],
      "metadata": {
        "id": "mvfqLiLRNSss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. 請問什麼是「過度擬合（Overfitting）」？該怎麼評估是否出現 Overfitting 的現象？**\n",
        "\n",
        "  過擬合表示模型在訓練數據上表現很好，但在測試數據上表現不好。這種現象的原因是模型過於複雜，導致在訓練數據上出現過度擬合的問題。  \n",
        "\n",
        "  要判斷一個模型是否存在過擬合，我們可以繪製學習曲線和驗證曲線來查看。  \n",
        "  以下情況表示發生過擬合現象：  \n",
        "  在學習曲線上訓練分數高出交叉驗證分數很多。  \n",
        "  在驗證曲線上顯示隨著模型複雜度增加，訓練分數增加而驗證分數下降。  \n",
        "\n",
        "  解決此問題的方法：  \n",
        "  簡化模型：減少特徵數量，降低模型複雜度。  \n",
        "  收集更多資料：增加訓練資料量，減少訓練資料的噪聲。  \n",
        "  使用正則化：在模型訓練過程中加入正則化項，控制模型複雜度。  "
      ],
      "metadata": {
        "id": "lAjhe_rkOjeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. 想一下如果是分群模型（例如 K-means），可以怎麼評估分群效果的好壞呢？**   \n",
        "\n",
        "  **inertia_** 值是一個評估指標。  \n",
        "  觀察 inertia_ 值和 K 值的關係圖，找到曲線上的\"彎曲點\"，也稱為\"肘點\"（Elbow point）。這個點代表著聚類數量增加對 inertia_ 值下降的效果逐漸減弱。  \n",
        "  一般而言，當 K 值逐漸增加時，inertia_ 值會呈現逐漸下降的趨勢。然而，隨著 K 值繼續增加，inertia_ 值的下降幅度會逐漸減小。當達到某一個 K 值後，inertia_ 值的下降趨勢出現明顯的變化，形成一個\"彎曲點\"。  \n",
        "  這個\"彎曲點\"對應的 K 值可以被視為最佳的聚類數量。選取該 K 值的理由是，在這個點之後增加聚類數量對聚類結果的改善效果有限，而增加聚類數量可能會導致過度分類的問題。  \n",
        "  因此，透過觀察 inertia_ 值和 K 值的關係圖，選取曲線上的\"彎曲點\"對應的 K 值，可以作為最佳的聚類數量。  \n",
        "\n",
        "  另一個評估指標為 **silhouette 分析** 。   \n",
        "  畫出K值和整體 silhouette 係數之間的關係圖。透過觀察關係圖，尋找 silhouette 係數最高的K值。較高的 silhouette 係數表示聚類結果較好，聚類內部的相似性較高，而聚類之間的差異性較大。選取具有最高 silhouette 係數的 K 值作為最佳的聚類數量。\n"
      ],
      "metadata": {
        "id": "5XO-KM-sQBKz"
      }
    }
  ]
}